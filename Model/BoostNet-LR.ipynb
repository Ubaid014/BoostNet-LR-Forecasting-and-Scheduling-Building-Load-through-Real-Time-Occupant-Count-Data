{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Decision trees\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Neural networks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Add, Input, Dense, Dropout, BatchNormalization, Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import layers\n",
    "from keras.layers import concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.regularizers import l1\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Wrapper to make neural network compitable with StackingRegressor\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Linear model as meta-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create generic dataset for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_occupant</th>\n",
       "      <th>Total_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.356876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.502624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.726831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.931956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.881140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_occupant  Total_load\n",
       "0               0    3.356876\n",
       "1               0    3.502624\n",
       "2               0    3.726831\n",
       "3               0    2.931956\n",
       "4               0    2.881140"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"hourly_load_data_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2592, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total_occupant    0\n",
       "Total_load        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_occupant</th>\n",
       "      <th>Total_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2592.000000</td>\n",
       "      <td>2592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.295139</td>\n",
       "      <td>7.412673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>92.936729</td>\n",
       "      <td>17.869472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.069164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>833.000000</td>\n",
       "      <td>96.526306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total_occupant   Total_load\n",
       "count     2592.000000  2592.000000\n",
       "mean        33.295139     7.412673\n",
       "std         92.936729    17.869472\n",
       "min          0.000000     0.000000\n",
       "25%          0.000000     0.000000\n",
       "50%          0.000000     0.000000\n",
       "75%          0.000000     3.069164\n",
       "max        833.000000    96.526306"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1= MinMaxScaler(feature_range=(0,1))\n",
    "X= s1.fit_transform(df)\n",
    "s2=MinMaxScaler(feature_range=(0,1))\n",
    "y= s2.fit_transform(df[['Total_load']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape (1814, 2)\n",
      "TEST set shape (778, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=42,shuffle=False)\n",
    "print('Train set shape', X_train1.shape)\n",
    "print('TEST set shape', X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape (1814, 2, 1)\n",
      "Test set shape (778, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_series=np.reshape(X_train1,(1814,2,1))\n",
    "X_test_series=np.reshape(X_test1,(778,2,1))\n",
    "print('Train set shape', X_train_series.shape)\n",
    "print('Test set shape', X_test_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_neural_network():\n",
    "    \n",
    "   model= Sequential()\n",
    "   model.add(LSTM(units = 96, activation='relu', input_shape=(2,1),return_sequences=True))\n",
    "   model.add(Dropout(0.1))\n",
    "   model.add(LSTM(units = 96, activation='relu',return_sequences=True))\n",
    "   model.add(Dropout(0.1))\n",
    "   model.add(LSTM(units = 64, activation='relu',return_sequences=True))\n",
    "   model.add(Dropout(0.1))\n",
    "   model.add(LSTM(units = 32, activation='relu',return_sequences=True,))\n",
    "   model.add(Dropout(0.1))\n",
    "   model.add(LSTM(units = 32, activation='relu'))\n",
    "   model.add(Dropout(0.1))\n",
    "# Adding the output layer   \n",
    "   model.add(Dense(units = 1,activation=\"linear\"))     \n",
    "\n",
    "   model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])\n",
    "    \n",
    "    \n",
    "   \n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking(input_shape=None):\n",
    "\n",
    "   \n",
    "    level0 = list()\n",
    "   \n",
    "    \n",
    "    level0.append(('xg', XGBRegressor(tree_method='approx',subsamples=0.7,n_estimators=300,max_depth=12,learning_rate=0.5,colsample_bytree=0.6)))\n",
    "    level0.append(('rf', RandomForestRegressor(n_estimators=20,min_samples_split=5,min_samples_leaf=2,max_samples= 0.75,max_features=0.6,max_depth= 2,bootstrap= True)))\n",
    "    \n",
    "    \n",
    "    for i in range(1):\n",
    "    \n",
    "        keras_reg = KerasRegressor(\n",
    "                create_neural_network, \n",
    "               \n",
    "                epochs=5,\n",
    "                verbose=2)\n",
    "        keras_reg._estimator_type = \"regressor\"\n",
    "        \n",
    "        level0.append(('nn_{num}'.format(num=i), keras_reg))\n",
    "   \n",
    "    level1 = LinearRegression()\n",
    "    \n",
    "  \n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunrise\\AppData\\Local\\Temp\\ipykernel_8568\\2401107453.py:13: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = KerasRegressor(\n",
      "c:\\Users\\sunrise\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:865: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"subsamples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "57/57 - 12s - loss: 0.0359 - root_mean_squared_error: 0.1895 - 12s/epoch - 205ms/step\n",
      "Epoch 2/5\n",
      "57/57 - 1s - loss: 0.0342 - root_mean_squared_error: 0.1849 - 564ms/epoch - 10ms/step\n",
      "Epoch 3/5\n",
      "57/57 - 1s - loss: 0.0329 - root_mean_squared_error: 0.1815 - 572ms/epoch - 10ms/step\n",
      "Epoch 4/5\n",
      "57/57 - 1s - loss: 0.0322 - root_mean_squared_error: 0.1795 - 564ms/epoch - 10ms/step\n",
      "Epoch 5/5\n",
      "57/57 - 1s - loss: 0.0318 - root_mean_squared_error: 0.1784 - 580ms/epoch - 10ms/step\n",
      "[14:02:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"subsamples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"subsamples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:02:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"subsamples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:02:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"subsamples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:02:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"subsamples\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "46/46 - 7s - loss: 0.0096 - root_mean_squared_error: 0.0980 - 7s/epoch - 155ms/step\n",
      "Epoch 2/5\n",
      "46/46 - 0s - loss: 0.0092 - root_mean_squared_error: 0.0961 - 440ms/epoch - 10ms/step\n",
      "Epoch 3/5\n",
      "46/46 - 0s - loss: 0.0091 - root_mean_squared_error: 0.0953 - 444ms/epoch - 10ms/step\n",
      "Epoch 4/5\n",
      "46/46 - 0s - loss: 0.0090 - root_mean_squared_error: 0.0950 - 448ms/epoch - 10ms/step\n",
      "Epoch 5/5\n",
      "46/46 - 0s - loss: 0.0090 - root_mean_squared_error: 0.0949 - 448ms/epoch - 10ms/step\n",
      "12/12 - 1s - 852ms/epoch - 71ms/step\n",
      "Epoch 1/5\n",
      "46/46 - 7s - loss: 0.0358 - root_mean_squared_error: 0.1891 - 7s/epoch - 161ms/step\n",
      "Epoch 2/5\n",
      "46/46 - 0s - loss: 0.0347 - root_mean_squared_error: 0.1862 - 496ms/epoch - 11ms/step\n",
      "Epoch 3/5\n",
      "46/46 - 0s - loss: 0.0338 - root_mean_squared_error: 0.1839 - 460ms/epoch - 10ms/step\n",
      "Epoch 4/5\n",
      "46/46 - 0s - loss: 0.0333 - root_mean_squared_error: 0.1825 - 464ms/epoch - 10ms/step\n",
      "Epoch 5/5\n",
      "46/46 - 0s - loss: 0.0330 - root_mean_squared_error: 0.1817 - 456ms/epoch - 10ms/step\n",
      "12/12 - 1s - 860ms/epoch - 72ms/step\n",
      "Epoch 1/5\n",
      "46/46 - 8s - loss: 0.0453 - root_mean_squared_error: 0.2129 - 8s/epoch - 163ms/step\n",
      "Epoch 2/5\n",
      "46/46 - 0s - loss: 0.0434 - root_mean_squared_error: 0.2083 - 488ms/epoch - 11ms/step\n",
      "Epoch 3/5\n",
      "46/46 - 0s - loss: 0.0416 - root_mean_squared_error: 0.2040 - 480ms/epoch - 10ms/step\n",
      "Epoch 4/5\n",
      "46/46 - 0s - loss: 0.0402 - root_mean_squared_error: 0.2006 - 488ms/epoch - 11ms/step\n",
      "Epoch 5/5\n",
      "46/46 - 0s - loss: 0.0392 - root_mean_squared_error: 0.1980 - 488ms/epoch - 11ms/step\n",
      "12/12 - 1s - 945ms/epoch - 79ms/step\n",
      "Epoch 1/5\n",
      "46/46 - 7s - loss: 0.0451 - root_mean_squared_error: 0.2124 - 7s/epoch - 156ms/step\n",
      "Epoch 2/5\n",
      "46/46 - 0s - loss: 0.0430 - root_mean_squared_error: 0.2075 - 472ms/epoch - 10ms/step\n",
      "Epoch 3/5\n",
      "46/46 - 0s - loss: 0.0413 - root_mean_squared_error: 0.2032 - 476ms/epoch - 10ms/step\n",
      "Epoch 4/5\n",
      "46/46 - 0s - loss: 0.0399 - root_mean_squared_error: 0.1999 - 468ms/epoch - 10ms/step\n",
      "Epoch 5/5\n",
      "46/46 - 0s - loss: 0.0389 - root_mean_squared_error: 0.1972 - 468ms/epoch - 10ms/step\n",
      "12/12 - 1s - 848ms/epoch - 71ms/step\n",
      "Epoch 1/5\n",
      "46/46 - 8s - loss: 0.0455 - root_mean_squared_error: 0.2132 - 8s/epoch - 166ms/step\n",
      "Epoch 2/5\n",
      "46/46 - 0s - loss: 0.0440 - root_mean_squared_error: 0.2097 - 490ms/epoch - 11ms/step\n",
      "Epoch 3/5\n",
      "46/46 - 0s - loss: 0.0426 - root_mean_squared_error: 0.2064 - 496ms/epoch - 11ms/step\n",
      "Epoch 4/5\n",
      "46/46 - 0s - loss: 0.0411 - root_mean_squared_error: 0.2028 - 492ms/epoch - 11ms/step\n",
      "Epoch 5/5\n",
      "46/46 - 0s - loss: 0.0401 - root_mean_squared_error: 0.2002 - 493ms/epoch - 11ms/step\n",
      "12/12 - 1s - 857ms/epoch - 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   53.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;xg&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.6,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.5, max_bin=None,\n",
       "                                            m...\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None, ...)),\n",
       "                              (&#x27;rf&#x27;,\n",
       "                               RandomForestRegressor(max_depth=2,\n",
       "                                                     max_features=0.6,\n",
       "                                                     max_samples=0.75,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_estimators=20)),\n",
       "                              (&#x27;nn_0&#x27;,\n",
       "                               &lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000273F0F4EA10&gt;)],\n",
       "                  final_estimator=LinearRegression(), verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;xg&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.6,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.5, max_bin=None,\n",
       "                                            m...\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None, ...)),\n",
       "                              (&#x27;rf&#x27;,\n",
       "                               RandomForestRegressor(max_depth=2,\n",
       "                                                     max_features=0.6,\n",
       "                                                     max_samples=0.75,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_estimators=20)),\n",
       "                              (&#x27;nn_0&#x27;,\n",
       "                               &lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000273F0F4EA10&gt;)],\n",
       "                  final_estimator=LinearRegression(), verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xg</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.6, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=300, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=2, max_features=0.6, max_samples=0.75,\n",
       "                      min_samples_leaf=2, min_samples_split=5, n_estimators=20)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>nn_0</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000273F0F4EA10&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('xg',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.6,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.5, max_bin=None,\n",
       "                                            m...\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None, ...)),\n",
       "                              ('rf',\n",
       "                               RandomForestRegressor(max_depth=2,\n",
       "                                                     max_features=0.6,\n",
       "                                                     max_samples=0.75,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_estimators=20)),\n",
       "                              ('nn_0',\n",
       "                               <keras.wrappers.scikit_learn.KerasRegressor object at 0x00000273F0F4EA10>)],\n",
       "                  final_estimator=LinearRegression(), verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = get_stacking()\n",
    "model.fit(X_train1, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 1s - 950ms/epoch - 38ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.24274871e-02, -1.79094205e-02,\n",
       "       -1.26502509e-02, -1.26221181e-02, -1.26946188e-02, -1.27223824e-02,\n",
       "       -1.26229650e-02, -2.88811984e-03,  4.48169699e-01,  4.30596040e-01,\n",
       "        4.30671350e-01,  4.57886103e-01,  4.69084160e-01,  4.69635170e-01,\n",
       "        5.16758141e-01,  4.69570387e-01,  4.56790338e-01,  4.26336534e-01,\n",
       "        2.18563396e-01,  2.62542974e-01,  1.61099149e-01,  2.55563902e-02,\n",
       "        2.78657554e-02,  2.22339555e-02,  2.64342816e-03, -1.26939389e-02,\n",
       "       -1.28783376e-02, -1.26943086e-02, -1.26955372e-02, -1.26094176e-02,\n",
       "       -1.26957997e-02, -1.16325325e-04,  4.24242949e-01,  4.39749059e-01,\n",
       "        4.73196395e-01,  6.54057983e-01,  6.68673093e-01,  6.77668154e-01,\n",
       "        6.77437978e-01,  6.81858146e-01,  4.67640351e-01,  4.28117832e-01,\n",
       "        4.51808954e-01,  2.18304232e-01,  2.08740378e-01,  2.44354723e-02,\n",
       "        2.92727206e-02,  1.65752761e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02,  1.55120400e-02,  1.55885902e-02,\n",
       "        2.02652368e-04, -1.27822521e-02, -1.26943086e-02, -1.62341411e-02,\n",
       "       -1.26219749e-02, -1.78762691e-03,  5.68716315e-01,  6.03062590e-01,\n",
       "        6.58065249e-01,  6.72412804e-01,  6.62578576e-01,  6.87075529e-01,\n",
       "        6.85666500e-01,  4.84870652e-01,  4.72734378e-01,  4.93074264e-01,\n",
       "        4.60457498e-01,  2.24499138e-01,  2.16598333e-01,  1.63451040e-01,\n",
       "        7.18549344e-02,  1.65453962e-02,  1.97108427e-03, -1.26410182e-02,\n",
       "       -1.24961921e-02, -1.26405053e-02, -1.26230127e-02, -1.26939031e-02,\n",
       "       -1.25618900e-02,  2.64286754e-03,  5.67574894e-01,  4.30402155e-01,\n",
       "        4.56841953e-01,  6.89765325e-01,  6.88096569e-01,  5.12767956e-01,\n",
       "        4.74060514e-01,  5.11524502e-01,  5.01336679e-01,  4.69475660e-01,\n",
       "        4.77723526e-01,  2.08197731e-01,  2.12876842e-01,  6.83456805e-02,\n",
       "        6.76481611e-02,  4.81366920e-02,  1.55886737e-02,  2.65527256e-02,\n",
       "        3.12513659e-03, -1.26940582e-02, -1.26221777e-02, -1.45733014e-02,\n",
       "       -1.27432747e-02, -1.80684717e-02,  5.30218056e-01,  6.16583493e-01,\n",
       "        6.63316601e-01,  6.81273570e-01,  6.85358462e-01,  6.78979927e-01,\n",
       "        5.02461707e-01,  4.97608920e-01,  4.70591921e-01,  5.28868930e-01,\n",
       "        4.33774115e-01,  1.63867250e-01,  1.75183293e-01,  2.52013758e-02,\n",
       "        1.99615910e-02,  3.47551782e-04, -1.26932948e-02, -1.27044032e-02,\n",
       "       -1.26235256e-02, -1.30955076e-02, -1.24958343e-02, -1.27846735e-02,\n",
       "       -1.25895176e-02,  7.21401336e-02,  5.29796577e-01,  6.63964745e-01,\n",
       "        4.49227807e-01,  5.05104562e-01,  4.71890646e-01,  5.36212107e-01,\n",
       "        4.88328615e-01,  5.06317943e-01,  4.71212863e-01,  4.56583461e-01,\n",
       "        4.31479033e-01,  2.16001996e-01,  2.13190394e-01,  1.59110165e-01,\n",
       "        1.32297003e-01,  4.37039554e-02,  1.57947026e-02,  1.01058651e-02,\n",
       "        1.55878984e-02,  6.92722384e-04, -1.27835523e-02, -1.24950351e-02,\n",
       "       -1.26220346e-02, -1.26224640e-02,  5.78181949e-01,  6.61020861e-01,\n",
       "        6.63396834e-01,  7.28726704e-01,  6.88210419e-01,  7.28252967e-01,\n",
       "        7.27813794e-01,  7.28877279e-01,  6.27146363e-01,  4.52719712e-01,\n",
       "        4.35399924e-01,  2.78491619e-01,  2.40350781e-01,  1.38300554e-01,\n",
       "        6.97890956e-02,  6.55287665e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02, -1.36848877e-02, -1.36848877e-02,\n",
       "       -1.36848877e-02, -1.36848877e-02,  1.93522769e-02,  1.22258565e-02,\n",
       "        1.01058055e-02,  2.10712620e-02, -1.25909179e-02, -1.25914189e-02,\n",
       "       -1.26219630e-02,  3.41710420e-02,  5.01895037e-01,  5.88005961e-01,\n",
       "        6.04759536e-01,  6.60312257e-01,  6.45582206e-01,  6.60912650e-01,\n",
       "        6.06710169e-01,  6.54380687e-01,  4.91468001e-01,  4.62926725e-01,\n",
       "        4.31584010e-01,  2.72928109e-01,  1.72730632e-01,  7.61609104e-02,\n",
       "        8.34846665e-02,  7.96121105e-02,  5.70084284e-02,  4.17400915e-02,\n",
       "        4.17396502e-02,  4.17427634e-02,  4.17434791e-02,  4.17368471e-02,\n",
       "        4.17519242e-02,  4.17599756e-02,  6.84154339e-02,  4.61990363e-01,\n",
       "        6.60056560e-01,  4.80977190e-01,  6.16733666e-01,  6.88881654e-01,\n",
       "        6.50489116e-01,  6.61999391e-01,  5.81907649e-01,  4.69293776e-01,\n",
       "        3.70411221e-02,  2.20961746e-02,  4.95637616e-02,  8.38009816e-02,\n",
       "        8.37992401e-02,  2.95377076e-02,  2.37518168e-03, -1.22194068e-02,\n",
       "       -1.22188104e-02, -1.22177011e-02, -1.58668211e-02, -1.22181663e-02,\n",
       "       -1.22207189e-02,  4.05137265e-02,  5.24615649e-01,  5.07716231e-01,\n",
       "        6.58971706e-01,  6.83815501e-01,  6.43342385e-01,  6.99025110e-01,\n",
       "        6.68764631e-01,  7.18020101e-01,  5.84407540e-01,  4.33467829e-01,\n",
       "        2.24848438e-01,  4.66619946e-02,  6.97420104e-02,  2.80892330e-02,\n",
       "        2.80885770e-02,  2.42653690e-02,  1.10905414e-02, -1.50919924e-02,\n",
       "       -1.22198601e-02, -1.22189297e-02, -1.22188462e-02, -1.51351411e-02,\n",
       "       -1.50918015e-02, -1.22187508e-02,  5.07270419e-01,  4.48875615e-01,\n",
       "        4.66110843e-01,  4.76347108e-01,  4.58904224e-01,  4.36394687e-01,\n",
       "        6.72467259e-01,  6.69222454e-01,  6.70377920e-01,  4.74322599e-01,\n",
       "        4.34517973e-01,  1.66508588e-01,  2.21547192e-01,  2.79140580e-02,\n",
       "        2.79134138e-02,  2.81031651e-02])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction = prediction.reshape(prediction.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred= s2.inverse_transform(Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03905554],\n",
       "       [0.03947477],\n",
       "       [0.03242584],\n",
       "       [0.03287048],\n",
       "       [0.03107027],\n",
       "       [0.03036509],\n",
       "       [0.03314252],\n",
       "       [0.06376268],\n",
       "       [0.41879907],\n",
       "       [0.33664693],\n",
       "       [0.32031881],\n",
       "       [0.38267477],\n",
       "       [0.41306756],\n",
       "       [0.40219848],\n",
       "       [0.50821104],\n",
       "       [0.33057609],\n",
       "       [0.31265483],\n",
       "       [0.27474126],\n",
       "       [0.17730649],\n",
       "       [0.14369786],\n",
       "       [0.0549103 ],\n",
       "       [0.04029019],\n",
       "       [0.03880858],\n",
       "       [0.04312503],\n",
       "       [0.03292313],\n",
       "       [0.03084946],\n",
       "       [0.03826264],\n",
       "       [0.03096978],\n",
       "       [0.03136955],\n",
       "       [0.03381854],\n",
       "       [0.03145393],\n",
       "       [0.0789319 ],\n",
       "       [0.43295186],\n",
       "       [0.32112033],\n",
       "       [0.51842933],\n",
       "       [0.71770924],\n",
       "       [0.75837   ],\n",
       "       [0.74444197],\n",
       "       [0.67411648],\n",
       "       [0.63244738],\n",
       "       [0.47796809],\n",
       "       [0.45563685],\n",
       "       [0.32243578],\n",
       "       [0.06540644],\n",
       "       [0.06194405],\n",
       "       [0.04660953],\n",
       "       [0.03765921],\n",
       "       [0.03916005],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.03673998],\n",
       "       [0.03870105],\n",
       "       [0.0351465 ],\n",
       "       [0.02838276],\n",
       "       [0.03096991],\n",
       "       [0.02817585],\n",
       "       [0.03282432],\n",
       "       [0.06626157],\n",
       "       [0.74656947],\n",
       "       [0.54951853],\n",
       "       [0.6180218 ],\n",
       "       [0.57202848],\n",
       "       [0.5992254 ],\n",
       "       [0.61156   ],\n",
       "       [0.57497361],\n",
       "       [0.47075157],\n",
       "       [0.44565509],\n",
       "       [0.49099547],\n",
       "       [0.38770531],\n",
       "       [0.0619677 ],\n",
       "       [0.05497767],\n",
       "       [0.04787008],\n",
       "       [0.04262777],\n",
       "       [0.03917193],\n",
       "       [0.03888595],\n",
       "       [0.03278092],\n",
       "       [0.03726403],\n",
       "       [0.03261424],\n",
       "       [0.03315643],\n",
       "       [0.03083913],\n",
       "       [0.03490685],\n",
       "       [0.03310676],\n",
       "       [0.57446078],\n",
       "       [0.46048811],\n",
       "       [0.3741514 ],\n",
       "       [0.7225181 ],\n",
       "       [0.6528705 ],\n",
       "       [0.45139339],\n",
       "       [0.42344267],\n",
       "       [0.38634169],\n",
       "       [0.3965168 ],\n",
       "       [0.40815561],\n",
       "       [0.50543489],\n",
       "       [0.06055266],\n",
       "       [0.05249289],\n",
       "       [0.0443744 ],\n",
       "       [0.04126658],\n",
       "       [0.04164256],\n",
       "       [0.03867537],\n",
       "       [0.0389034 ],\n",
       "       [0.04095926],\n",
       "       [0.03088931],\n",
       "       [0.03289037],\n",
       "       [0.03513134],\n",
       "       [0.02952234],\n",
       "       [0.049035  ],\n",
       "       [0.73393007],\n",
       "       [0.64685861],\n",
       "       [0.63663781],\n",
       "       [0.60214559],\n",
       "       [0.57173368],\n",
       "       [0.5711783 ],\n",
       "       [0.50644017],\n",
       "       [0.52142749],\n",
       "       [0.51195003],\n",
       "       [0.53052397],\n",
       "       [0.42588538],\n",
       "       [0.05714355],\n",
       "       [0.05520605],\n",
       "       [0.04422156],\n",
       "       [0.0392601 ],\n",
       "       [0.03929822],\n",
       "       [0.03064444],\n",
       "       [0.03037573],\n",
       "       [0.0333244 ],\n",
       "       [0.03401565],\n",
       "       [0.03714537],\n",
       "       [0.02917042],\n",
       "       [0.0339153 ],\n",
       "       [0.11950581],\n",
       "       [0.76697255],\n",
       "       [0.9313113 ],\n",
       "       [0.47116381],\n",
       "       [0.44476601],\n",
       "       [0.50136411],\n",
       "       [0.49963911],\n",
       "       [0.49554397],\n",
       "       [0.45829447],\n",
       "       [0.44641871],\n",
       "       [0.42098145],\n",
       "       [0.437089  ],\n",
       "       [0.05955363],\n",
       "       [0.06025421],\n",
       "       [0.04636918],\n",
       "       [0.04775154],\n",
       "       [0.04783944],\n",
       "       [0.04324248],\n",
       "       [0.03937428],\n",
       "       [0.03892701],\n",
       "       [0.03503305],\n",
       "       [0.02880573],\n",
       "       [0.03688513],\n",
       "       [0.03284432],\n",
       "       [0.03298148],\n",
       "       [0.73136443],\n",
       "       [0.93697005],\n",
       "       [0.6305409 ],\n",
       "       [0.58469869],\n",
       "       [0.67208816],\n",
       "       [0.65896192],\n",
       "       [0.67086926],\n",
       "       [0.63960471],\n",
       "       [0.5567794 ],\n",
       "       [0.3959582 ],\n",
       "       [0.29808911],\n",
       "       [0.09124187],\n",
       "       [0.08415846],\n",
       "       [0.05826026],\n",
       "       [0.04196216],\n",
       "       [0.03916993],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.04101286],\n",
       "       [0.04127875],\n",
       "       [0.03939428],\n",
       "       [0.0391722 ],\n",
       "       [0.03412396],\n",
       "       [0.03428771],\n",
       "       [0.03281633],\n",
       "       [0.13250987],\n",
       "       [0.55822848],\n",
       "       [0.55215043],\n",
       "       [0.54557892],\n",
       "       [0.54071833],\n",
       "       [0.56726336],\n",
       "       [0.54432371],\n",
       "       [0.54675297],\n",
       "       [0.55718148],\n",
       "       [0.49330057],\n",
       "       [0.35485114],\n",
       "       [0.30710192],\n",
       "       [0.11482508],\n",
       "       [0.10834557],\n",
       "       [0.10808766],\n",
       "       [0.10810141],\n",
       "       [0.10850417],\n",
       "       [0.10825873],\n",
       "       [0.1090983 ],\n",
       "       [0.10924244],\n",
       "       [0.10824247],\n",
       "       [0.10801683],\n",
       "       [0.11013665],\n",
       "       [0.10530706],\n",
       "       [0.10272948],\n",
       "       [0.13553786],\n",
       "       [0.48648939],\n",
       "       [0.91519752],\n",
       "       [0.48285901],\n",
       "       [0.68306379],\n",
       "       [0.63193227],\n",
       "       [0.6443777 ],\n",
       "       [0.54066383],\n",
       "       [0.5402833 ],\n",
       "       [0.51211478],\n",
       "       [0.0632836 ],\n",
       "       [0.04614754],\n",
       "       [0.04317076],\n",
       "       [0.04251214],\n",
       "       [0.04307538],\n",
       "       [0.04281449],\n",
       "       [0.04476408],\n",
       "       [0.04295966],\n",
       "       [0.04276578],\n",
       "       [0.04240661],\n",
       "       [0.04491528],\n",
       "       [0.04255305],\n",
       "       [0.0433858 ],\n",
       "       [0.178112  ],\n",
       "       [0.62165381],\n",
       "       [0.55276483],\n",
       "       [0.73579754],\n",
       "       [0.74416105],\n",
       "       [0.63773676],\n",
       "       [0.65397194],\n",
       "       [0.65290192],\n",
       "       [0.62022259],\n",
       "       [0.54140384],\n",
       "       [0.37395845],\n",
       "       [0.24177728],\n",
       "       [0.04441679],\n",
       "       [0.04319359],\n",
       "       [0.04260021],\n",
       "       [0.04281193],\n",
       "       [0.04500181],\n",
       "       [0.04317913],\n",
       "       [0.0445197 ],\n",
       "       [0.04310565],\n",
       "       [0.04280298],\n",
       "       [0.04277851],\n",
       "       [0.04238844],\n",
       "       [0.04445718],\n",
       "       [0.0427475 ],\n",
       "       [0.60209913],\n",
       "       [0.49075619],\n",
       "       [0.52002899],\n",
       "       [0.50563479],\n",
       "       [0.48130742],\n",
       "       [0.39832502],\n",
       "       [0.81134196],\n",
       "       [0.64486169],\n",
       "       [0.72198104],\n",
       "       [0.5103842 ],\n",
       "       [0.38769588],\n",
       "       [0.04671426],\n",
       "       [0.04308447],\n",
       "       [0.04263276],\n",
       "       [0.04284201],\n",
       "       [0.04296279]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual= s2.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(Pred,columns=[\"Prediciton\"])\n",
    "data=pd.DataFrame(Actual,columns=['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"E:\\Mam_iqra second paper\\School of Design and Environment 4 (SDE4), Singapor\\Stack_Model\\prediction.csv\")\n",
    "data.to_csv(r\"E:\\Mam_iqra second paper\\School of Design and Environment 4 (SDE4), Singapor\\Stack_Model\\Actual.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloumn_names: ['Prediction', 'Actual']\n",
      "Root Mean Square Error: 4.477010655306346\n",
      "Mean Square Error: 20.043624407726558\n",
      "Mean Absolute Error: 2.8530622389498714\n",
      "Normalized Root Mean Square Error 6.209453512339133\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df=pd.read_csv(\"output.csv\")\n",
    "features= list(df)\n",
    "print(\"cloumn_names:\",features)\n",
    "z= df[\"Actual\"]\n",
    "x= df[\"Prediction\"]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    " \n",
    "MSE = mean_squared_error(z,x)\n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE=mean_absolute_error(z,x)\n",
    "MAE\n",
    "max = x.max()\n",
    "min = x.min()\n",
    "NRMSE= (RMSE/(max-min))*100\n",
    "\n",
    "\n",
    "print(\"Root Mean Square Error:\",RMSE)\n",
    "print(\"Mean Square Error:\", MSE)\n",
    "print(\"Mean Absolute Error:\",MAE)\n",
    "print(\"Normalized Root Mean Square Error\",NRMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac4210170004fc925580c073d42b7c18005567bca7a1d143f4e4d5a93e6c63c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
