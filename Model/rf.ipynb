{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_occupant</th>\n",
       "      <th>Total_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.356876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.502624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.726831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.931956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.881140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_occupant  Total_load\n",
       "0               0    3.356876\n",
       "1               0    3.502624\n",
       "2               0    3.726831\n",
       "3               0    2.931956\n",
       "4               0    2.881140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"hourly_load_data_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2592, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total_occupant    0\n",
       "Total_load        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_occupant</th>\n",
       "      <th>Total_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2592.000000</td>\n",
       "      <td>2592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.295139</td>\n",
       "      <td>7.412673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>92.936729</td>\n",
       "      <td>17.869472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.069164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>833.000000</td>\n",
       "      <td>96.526306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total_occupant   Total_load\n",
       "count     2592.000000  2592.000000\n",
       "mean        33.295139     7.412673\n",
       "std         92.936729    17.869472\n",
       "min          0.000000     0.000000\n",
       "25%          0.000000     0.000000\n",
       "50%          0.000000     0.000000\n",
       "75%          0.000000     3.069164\n",
       "max        833.000000    96.526306"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1= MinMaxScaler(feature_range=(0,1))\n",
    "X= s1.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=MinMaxScaler(feature_range=(0,1))\n",
    "y= s2.fit_transform(df[['Total_load']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continential: 0.0800013542175293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunrise\\AppData\\Local\\Temp\\ipykernel_14228\\2465092350.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestRegressor(n_estimators=20,min_samples_split=5,min_samples_leaf=2,max_samples= 0.75,max_features=0.6,max_depth= 2,bootstrap= True)\n",
    "import time\n",
    "start= time.time()\n",
    "model.fit(X_train,y_train)\n",
    "end=time.time()\n",
    "continential=end-start\n",
    "print(\"continential:\",continential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continential: 0.01600027084350586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.05109165, 0.35795895, 0.38383841, 0.41845285, 0.46002683,\n",
       "       0.46002683, 0.46002683, 0.46002683, 0.46002683, 0.43971731,\n",
       "       0.38383841, 0.22814152, 0.25498059, 0.17779899, 0.09092198,\n",
       "       0.09092198, 0.09092198, 0.05109165, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.01139161,\n",
       "       0.34370875, 0.36337047, 0.38383841, 0.56291209, 0.57129612,\n",
       "       0.58417654, 0.58417654, 0.58417654, 0.42683689, 0.41845285,\n",
       "       0.42683689, 0.23083294, 0.23083294, 0.09092198, 0.09092198,\n",
       "       0.09092198, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.06795373,\n",
       "       0.06795373, 0.05109165, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.05109165, 0.40720803, 0.49429964, 0.56291209,\n",
       "       0.57129612, 0.57129612, 0.60448607, 0.60448607, 0.46002683,\n",
       "       0.46002683, 0.46002683, 0.43971731, 0.27383141, 0.26544738,\n",
       "       0.17779899, 0.11466735, 0.09092198, 0.05109165, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.05109165, 0.40720803, 0.38383841, 0.43971731, 0.60448607,\n",
       "       0.60448607, 0.4879584 , 0.46002683, 0.4879584 , 0.48170166,\n",
       "       0.43971731, 0.38383841, 0.21403248, 0.23083294, 0.11466735,\n",
       "       0.11466735, 0.1063987 , 0.06795373, 0.06795373, 0.06089866,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.39295783, 0.43371664, 0.57129612, 0.58417654, 0.60448607,\n",
       "       0.60448607, 0.43971731, 0.45691541, 0.41845285, 0.43913642,\n",
       "       0.38383841, 0.17779899, 0.17779899, 0.09092198, 0.09092198,\n",
       "       0.06089866, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.10184677, 0.40276484,\n",
       "       0.51984953, 0.38383841, 0.4879584 , 0.42683689, 0.4879584 ,\n",
       "       0.46002683, 0.4879584 , 0.46002683, 0.43971731, 0.38383841,\n",
       "       0.23083294, 0.23083294, 0.17779899, 0.137938  , 0.1063987 ,\n",
       "       0.06795373, 0.06795373, 0.06795373, 0.05109165, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.40720803, 0.52829765,\n",
       "       0.57129612, 0.63241764, 0.60448607, 0.63241764, 0.63241764,\n",
       "       0.63241764, 0.58740158, 0.43971731, 0.4055688 , 0.27178105,\n",
       "       0.23836974, 0.14735692, 0.11466735, 0.11466735, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.09092198, 0.06795373, 0.06795373,\n",
       "       0.06795373, 0.00385482, 0.00385482, 0.00385482, 0.04480293,\n",
       "       0.39012355, 0.49429964, 0.51848307, 0.5643535 , 0.56291209,\n",
       "       0.57960458, 0.53136349, 0.61533315, 0.46002683, 0.43971731,\n",
       "       0.38383841, 0.27178105, 0.16835745, 0.13187009, 0.13187009,\n",
       "       0.13187009, 0.09203976, 0.04480293, 0.04480293, 0.04480293,\n",
       "       0.04480293, 0.04480293, 0.04480293, 0.04480293, 0.10890184,\n",
       "       0.36337047, 0.4442453 , 0.43971731, 0.43371664, 0.60448607,\n",
       "       0.52829765, 0.5643535 , 0.46023351, 0.38383841, 0.1063987 ,\n",
       "       0.09092198, 0.1063987 , 0.11466735, 0.11466735, 0.09092198,\n",
       "       0.06089866, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.04480293, 0.39295783, 0.37321003,\n",
       "       0.45282576, 0.60448607, 0.52829765, 0.61994752, 0.57129612,\n",
       "       0.61994752, 0.47548459, 0.38383841, 0.24333129, 0.1063987 ,\n",
       "       0.11466735, 0.09092198, 0.09092198, 0.09092198, 0.06089866,\n",
       "       0.00385482, 0.00385482, 0.00385482, 0.00385482, 0.00385482,\n",
       "       0.00385482, 0.00385482, 0.35029819, 0.39412888, 0.39447812,\n",
       "       0.41845285, 0.38383841, 0.38383841, 0.57129612, 0.56291209,\n",
       "       0.57129612, 0.41845285, 0.38247958, 0.17779899, 0.21403248,\n",
       "       0.09092198, 0.09092198, 0.09092198])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=time.time()\n",
    "pred = model.predict(X_test)\n",
    "end=time.time()\n",
    "continential=end-start\n",
    "print(\"continential:\",continential)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pred.reshape(pred.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred= s2.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual= s2.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Pred\n",
    "z= Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculated = pd.DataFrame(Pred, columns = ['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculated.to_csv(r'E:\\Mam_iqra second paper\\School of Design and Environment 4 (SDE4), Singapor\\RF\\prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual = pd.DataFrame(Actual, columns = ['Actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actual.to_csv(r'E:\\Mam_iqra second paper\\School of Design and Environment 4 (SDE4), Singapor\\RF\\Actual.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloumn_names: ['Actual', 'Prediction']\n",
      "Root Mean Square Error: 5.7762920176539145\n",
      "Mean Square Error: 33.36554947321233\n",
      "Mean Absolute Error: 2.6130329508251924\n",
      "Normalized Root Mean Square Error 9.5203905362419\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df=pd.read_csv(\"output.csv\")\n",
    "features= list(df)\n",
    "print(\"cloumn_names:\",features)\n",
    "z= df[\"Actual\"]\n",
    "x= df[\"Prediction\"]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    " \n",
    "MSE = mean_squared_error(z,x)\n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE=mean_absolute_error(z,x)\n",
    "MAE\n",
    "max = x.max()\n",
    "min = x.min()\n",
    "NRMSE= (RMSE/(max-min))*100\n",
    "\n",
    "\n",
    "print(\"Root Mean Square Error:\",RMSE)\n",
    "print(\"Mean Square Error:\", MSE)\n",
    "print(\"Mean Absolute Error:\",MAE)\n",
    "print(\"Normalized Root Mean Square Error\",NRMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac4210170004fc925580c073d42b7c18005567bca7a1d143f4e4d5a93e6c63c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
